import pickle
from pathlib import Path

import torch
import torch.nn.functional as F
from jaxtyping import Float
from torch.distributions import categorical
from torch.utils.data import Dataset, random_split


class IsingDataset(Dataset):
    """Torch Dataset for Erdos Renyi Ising distributed samples.

    The samples are generated from Oops I took a gradient code. There are two valid configurations:

        1. A graph with 100 nodes and average degree 2
        2. A graph with 200 nodes and average degree 4

    For each configurations, there are five datasets, generated with different seeds. They have been generated by
    first sampling an adjacency matrix from an Erdos Renyi distribution with the given parameters, then defining an Ising model,
    and lastly sampling from the Ising model using Gibbs sampling, ran for 1 000 000 steps.


    Attributes:
        nb_nodes: int, number of nodes in the graph. 100 or 200.
        average_degree: int, average degree of the graph. 2 or 4.
        samples: Float[torch.Tensor, "2000 nb_nodes"], samples from the Ising model.
        J: Float[torch.Tensor, "nb_nodes nb_nodes"], the adjacency matrix of the graph.
    """

    def __init__(
        self,
        samples: Float[torch.Tensor, "nb_samples nb_nodes"],
        nb_nodes: int,
        average_degree: int,
        seed: int,
    ) -> None:
        """Initialize the dataset by unpacking the samples from a pickle file located under ../../GWG_DATASETS
        Args:
            samples: Float[torch.Tensor, "nb_samples nb_nodes"], samples from the Ising model.
            nb_nodes: int, number of nodes in the graph. 100 or 200.
            average_degree: int, average degree of the graph. 2 or 4.
            seed: int, seed used to generate the samples. Must be 1111, 2222, 3333, 4444 or 5555.

        Raises:
            AssertionError: if seed is not 1111, 2222, 3333, 4444 or 5555
            AssertionError: if nb_nodes is not 100 and average_degree is not 2 or if nb_nodes is not 200 and average_degree is not 4
        """

        self.nb_nodes = nb_nodes
        self.average_degree = average_degree
        self.samples = samples
        self.nb_samples = samples.shape[0]

    def __len__(self):
        return self.nb_samples

    def __getitem__(self, index: int) -> Float[torch.Tensor, "nb_nodes"]:
        return (self.samples[index], torch.zeros(self.nb_nodes))


class Ising:
    """Holders for train, val and test datasets for Categorical

    Attributes:
        dataset_train: IsingDataset, dataset for training
        dataset_val: IsingDataset, dataset for validation
        dataset_test: IsingDataset, dataset for testing
        J$: Float[torch.Tensor, "nb_nodes nb_nodes"], the adjacency matrix of the graph.
    """

    def __init__(
        self,
        nb_nodes: int,
        average_degree: int,
        seed: int,
        percent_val: float = None,
        percent_test: float = None,
    ):
        """Initialize the datasets
        Args:
            nb_nodes: int, number of nodes in the graph. 100 or 200.
            average_degree: int, average degree of the graph. 2 or 4.
            seed: int, seed used to generate the samples. Must be 1111, 2222, 3333, 4444 or 5555.
            percent_val: float, percentage of the training set to use for validation. If None, 10% of the training set is used.
            percent_test: float, percentage of the training set to use for testing. If None, 10% of the training set is used.

        Raises:
            AssertionError: if seed is not 1111, 2222, 3333, 4444 or 5555
            AssertionError: if nb_nodes is not 100 and average_degree is not 2 or if nb_nodes is not 200 and average_degree is not 4
            AssertionError: if percent_val + percent_test is greater than 1
        """
        assert seed in [
            1111,
            2222,
            3333,
            4444,
            5555,
        ], f"seed must be 1111, 2222, 3333, 4444 or 5555 and got {seed}"
        assert (
            nb_nodes == 100
            and average_degree == 2
            or nb_nodes == 200
            and average_degree == 4
        )
        self.nb_nodes = nb_nodes
        self.average_degree = average_degree

        if percent_val is None:
            percent_val = 0.1
        if percent_test is None:
            percent_test = 0.1

        assert (
            percent_val + percent_test < 1
        ), "percent_val + percent_test must be less than 1"

        percent_train = 1 - percent_val - percent_test

        directory = Path.cwd() / (
            f"Dataset/MissingDataDataset/DiscreteDataset/GWG_DATASETS/ising_er_nodes_{nb_nodes}_conn_{average_degree}_seed_{seed}"
        )
        data_path = f"{directory}/data.pkl"
        J_path = f"{directory}/J.pkl"

        with open(data_path, "rb") as f:
            samples = pickle.load(f)

        with open(J_path, "rb") as f:
            self.J = pickle.load(f)

        nb_samples = samples.shape[0]
        shuffled_samples = samples[torch.randperm(nb_samples)]
        samples_train = shuffled_samples[: int(nb_samples * percent_train)]
        samples_val = shuffled_samples[
            int(nb_samples * percent_train) : int(
                nb_samples * (percent_train + percent_val)
            )
        ]
        samples_test = shuffled_samples[
            int(nb_samples * (percent_train + percent_val)) :
        ]

        assert len(samples_train) + len(samples_val) + len(samples_test) == nb_samples
        assert len(samples_train) > 0
        assert len(samples_val) > 0
        assert len(samples_test) > 0

        self.dataset_train = IsingDataset(samples_train, nb_nodes, average_degree, seed)
        self.dataset_val = IsingDataset(samples_val, nb_nodes, average_degree, seed)
        self.dataset_test = IsingDataset(samples_test, nb_nodes, average_degree, seed)

    def get_dim_input(self):
        return (1, self.nb_nodes)

    def get_dim_output(self):
        return (self.nb_nodes,)

    def transform_back(self, x):
        """Method to make it work with Abstract Trainer"""
        return None
