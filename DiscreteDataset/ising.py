import pickle

import torch
import torch.nn.functional as F
from jaxtyping import Float
from torch.distributions import categorical
from torch.utils.data import Dataset, random_split


class IsingDataset(Dataset):
    """Torch Dataset for Erdos Renyi Ising distributed samples.

    The samples are generated from Oops I took a gradient code. There are two valid configurations:

        1. A graph with 100 nodes and average degree 2
        2. A graph with 200 nodes and average degree 4

    For each configurations, there are five datasets, generated with different seeds. They have been generated by
    first sampling an adjacency matrix from an Erdos Renyi distribution with the given parameters, then defining an Ising model,
    and lastly sampling from the Ising model using Gibbs sampling, ran for 1 000 000 steps.


    Attributes:
        nb_nodes: int, number of nodes in the graph. 100 or 200.
        average_degree: int, average degree of the graph. 2 or 4.
        samples: Float[torch.Tensor, "2000 nb_nodes"], samples from the Ising model.
        J: Float[torch.Tensor, "nb_nodes nb_nodes"], the adjacency matrix of the graph.
    """

    def __init__(self, nb_nodes: int, average_degree: int, seed: int) -> None:
        """Initialize the dataset by unpacking the samples from a pickle file located under ../../GWG_DATASETS
        Args:
            nb_nodes: int, number of nodes in the graph. 100 or 200.
            average_degree: int, average degree of the graph. 2 or 4.

            seed: int, seed used to generate the samples. Must be 1111, 2222, 3333, 4444 or 5555.

        Raises:
            AssertionError: if nb_nodes is not 100 or 200
            AssertionError: if average_degree is not 2 or 4
            AssertionError: if seed is not 1111, 2222, 3333, 4444 or 5555
        """
        assert nb_nodes in [100, 200], f"nb_nodes must be 100 or 200 and got {nb_nodes}"
        assert average_degree in [
            2,
            4,
        ], f"average_degree must be 2 or 4 and got {average_degree}"
        assert seed in [
            1111,
            2222,
            3333,
            4444,
            5555,
        ], f"seed must be 1111, 2222, 3333, 4444 or 5555 and got {seed}"
        self.nb_nodes = nb_nodes
        self.average_degree = average_degree
        directory = (
            f".GWG_DATASETS/ising_er_nodes_{nb_nodes}_conn_{average_degree}_seed_{seed}"
        )
        data_path = f"{directory}/data.pkl"
        J_path = f"{directory}/J.pkl"

        with open(data_path, "rb") as f:
            self.samples = pickle.load(f)

        with open(J_path, "rb") as f:
            self.J = pickle.load(f)

    def __len__(self):
        return self.samples.shape[0]

    def __getitem__(self, index: int) -> Float[torch.Tensor, "nb_nodes"]:
        return (self.samples[index], torch.zeros(self.nb_nodes))


class Ising:
    """Holders for train, val and test datasets for Categorical

    Attributes:
        dataset_train: IsingDataset, dataset for training
        dataset_val: IsingDataset, dataset for validation
        dataset_test: IsingDataset, dataset for testing
    """

    def __init__(
        self,
        nb_nodes: int,
        average_degree: int,
        seed: int,
        percent_val: float = None,
        percent_test: float = None,
    ):
        """Initialize the datasets
        Args:
            nb_nodes: int, number of nodes in the graph. 100 or 200.
            average_degree: int, average degree of the graph. 2 or 4.
            seed: int, seed used to generate the samples. Must be 1111, 2222, 3333, 4444 or 5555.
            percent_val: float, percentage of the training set to use for validation. If None, 10% of the training set is used.
            percent_test: float, percentage of the training set to use for testing. If None, 10% of the training set is used.
        """
        dataset = IsingDataset(nb_nodes, average_degree, seed)

        if percent_val is None:
            percent_val = 0.1
        if percent_test is None:
            percent_test = 0.1

        assert (
            percent_val + percent_test < 1
        ), "percent_val + percent_test must be less than 1"

        list_data = random_split(
            [1 - percent_val - percent_test, percent_val, percent_test], dataset
        )
        self.dataset_train = list_data[0]
        self.dataset_val = list_data[1]
        self.dataset_test = list_data[2]

    def get_dim_input(self):
        return (1, self.nb_nodes)

    def get_dim_output(self):
        return (self.nb_nodes,)

    def transform_back(self, x):
        """Method to make it work with Abstract Trainer"""
        return None
